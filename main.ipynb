{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install git+https://github.com/huggingface/transformers\n",
    "!pip install -q datasets loralib sentencepiece\n",
    "!pip -q install bitsandbytes accelerate xformers\n",
    "!pip -q install gradio\n",
    "!pip -q install torch\n",
    "!pip -q install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "openai.api_key = \"Paste your openai api key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import gradio as gr\n",
    "import openai\n",
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "# response to audio\n",
    "def tts(input_text):\n",
    "    inputs = processor(text=input_text, return_tensors=\"pt\")\n",
    "    embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "    speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "    speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "    audio_numpy = speech.numpy()\n",
    "    sample_rate = 16000\n",
    "\n",
    "    return(sample_rate,audio_numpy)\n",
    "\n",
    "# prompt response\n",
    "def openai_chat(prompt):\n",
    "    prompt = prompt + \"Respond in less than 50 words\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=250,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    audio_response = tts(response.choices[0].message.content)\n",
    "\n",
    "    return(response.choices[0].message.content,audio_response)\n",
    "\n",
    "#Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=openai_chat,\n",
    "    inputs=gr.Textbox(\"Hi how are you\", label=\"Converse with ChatGPT\"),\n",
    "    outputs=['text',gr.Audio(label=\"Audio Player\")],\n",
    "    live=False,\n",
    "    title=\"converse.ai\",\n",
    "    theme=\"light\",\n",
    "    layout=\"vertical\",\n",
    "    button=gr.Button(\"Submit\")\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
